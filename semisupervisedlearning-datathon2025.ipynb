{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "- pandas for data manipulation\n",
    "- numpy for numerical operations\n",
    "- scikit-learn for machine learning\n",
    "- XGBoost for gradient boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-03T16:08:18.856960Z",
     "iopub.status.busy": "2025-04-03T16:08:18.856530Z",
     "iopub.status.idle": "2025-04-03T16:08:18.862453Z",
     "shell.execute_reply": "2025-04-03T16:08:18.860673Z",
     "shell.execute_reply.started": "2025-04-03T16:08:18.856927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised Learning with XGBoost and Bootstrap Sampling\n",
    " \n",
    "This notebook implements an iterative semi-supervised learning approach to improve model performance by leveraging unlabeled test data. The process involves:\n",
    "1. Loading and preprocessing training and test data\n",
    "2. Training an XGBoost regression model on labeled data\n",
    "3. Using bootstrap sampling to estimate prediction uncertainty\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset\n",
    "Loading the dataset for analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:08:19.584361Z",
     "iopub.status.busy": "2025-04-03T16:08:19.584018Z",
     "iopub.status.idle": "2025-04-03T16:08:19.625548Z",
     "shell.execute_reply": "2025-04-03T16:08:19.624676Z",
     "shell.execute_reply.started": "2025-04-03T16:08:19.584337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"/kaggle/input/xgb-bestmodel-datathon2025/best_xgb_model.pkl\", \"rb\") as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Training Dataset\n",
    "Loading the training data for model development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:08:19.912015Z",
     "iopub.status.busy": "2025-04-03T16:08:19.911592Z",
     "iopub.status.idle": "2025-04-03T16:08:19.950590Z",
     "shell.execute_reply": "2025-04-03T16:08:19.949387Z",
     "shell.execute_reply.started": "2025-04-03T16:08:19.911981Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/kaggle/input/datathon2025/final_preprocessed_train.csv\")\n",
    "test_data = pd.read_csv(\"/kaggle/input/datathon2025/final_preprocessed_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "Training a neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:08:20.362729Z",
     "iopub.status.busy": "2025-04-03T16:08:20.362378Z",
     "iopub.status.idle": "2025-04-03T16:08:20.370541Z",
     "shell.execute_reply": "2025-04-03T16:08:20.369402Z",
     "shell.execute_reply.started": "2025-04-03T16:08:20.362704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data.drop(columns=[\"Unnamed: 0\"], inplace=True, errors=\"ignore\")\n",
    "test_data.drop(columns=[\"Unnamed: 0\"], inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Execution\n",
    "Executing code for data analysis or model development\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:08:22.125299Z",
     "iopub.status.busy": "2025-04-03T16:08:22.124960Z",
     "iopub.status.idle": "2025-04-03T16:08:22.129872Z",
     "shell.execute_reply": "2025-04-03T16:08:22.128636Z",
     "shell.execute_reply.started": "2025-04-03T16:08:22.125276Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "confidence_threshold = 60 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised Learning Loop\n",
    "This code implements an iterative semi-supervised learning approach where:\n",
    "1. An XGBoost model is trained on labeled data\n",
    "2. The model makes predictions on unlabeled test data\n",
    "3. Bootstrap sampling is used to estimate prediction uncertainty\n",
    "4. High confidence predictions (above threshold) are added to training data\n",
    "5. Process repeats until no more high confidence predictions remain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Model\n",
    "Training an XGBoost model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:08:22.673640Z",
     "iopub.status.busy": "2025-04-03T16:08:22.673271Z",
     "iopub.status.idle": "2025-04-03T16:08:28.942198Z",
     "shell.execute_reply": "2025-04-03T16:08:28.939883Z",
     "shell.execute_reply.started": "2025-04-03T16:08:22.673611Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Training model...\n",
      "Model saved: updated_xgb_model_iteration_1.pkl\n",
      "Iteration 2: Training model...\n",
      "Model saved: updated_xgb_model_iteration_2.pkl\n",
      "Iteration 3: Training model...\n",
      "Model saved: updated_xgb_model_iteration_3.pkl\n",
      "Iteration 4: Training model...\n",
      "Model saved: updated_xgb_model_iteration_4.pkl\n",
      "Iteration 5: Training model...\n",
      "Model saved: updated_xgb_model_iteration_5.pkl\n",
      "Iteration 6: Training model...\n",
      "No more high-confidence samples. Stopping training.\n",
      "Semi-supervised learning process completed.\n"
     ]
    }
   ],
   "source": [
    "while not test_data.empty:\n",
    "    print(f\"Iteration {iteration + 1}: Training model...\")\n",
    "\n",
    "    # Prepare training data\n",
    "    X_train = train_data.drop(columns=[\"SalePrice\"])\n",
    "    y_train = train_data[\"SalePrice\"]\n",
    "\n",
    "    # Train the model\n",
    "    model = xgb.XGBRegressor(objective=\"reg:squarederror\", n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Ensure test data does not contain 'SalePrice' or 'Confidence_Percentage'\n",
    "    test_features = test_data.drop(columns=[\"SalePrice\", \"Confidence_Percentage\"], errors=\"ignore\")\n",
    "\n",
    "    # Predict on test set\n",
    "    predictions = model.predict(test_features)\n",
    "\n",
    "    # Bootstrap sampling for uncertainty estimation\n",
    "    n_samples = 50\n",
    "    bootstrap_preds = []\n",
    "\n",
    "    for _ in range(n_samples):\n",
    "        sample_data = resample(test_features)\n",
    "        preds = model.predict(sample_data)\n",
    "        bootstrap_preds.append(preds)\n",
    "\n",
    "    bootstrap_preds = np.array(bootstrap_preds)\n",
    "\n",
    "    # Compute mean and standard deviation\n",
    "    mean_predictions = bootstrap_preds.mean(axis=0)\n",
    "    std_predictions = bootstrap_preds.std(axis=0)\n",
    "\n",
    "    confidence_percentage = 100 * (1 - (std_predictions / (std_predictions.max() + 1e-6)))\n",
    "    confidence_percentage = np.clip(confidence_percentage, 0, 100)\n",
    "\n",
    "    # Store results\n",
    "    results_df = test_data.copy()\n",
    "    results_df[\"SalePrice\"] = mean_predictions\n",
    "    results_df[\"Confidence_Percentage\"] = confidence_percentage\n",
    "\n",
    "    # Select high-confidence predictions\n",
    "    filtered_df = results_df[results_df[\"Confidence_Percentage\"] > confidence_threshold].drop(columns=[\"Confidence_Percentage\"])\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        print(\"No more high-confidence samples. Stopping training.\")\n",
    "        break\n",
    "\n",
    "    # Update training and test data\n",
    "    train_data = pd.concat([train_data, filtered_df], ignore_index=True)\n",
    "    test_data = test_data.drop(filtered_df.index).reset_index(drop=True)\n",
    "\n",
    "    train_data.to_csv(f\"final_train_data_ssl{iteration+1}.csv\")\n",
    "\n",
    "    # Save updated model\n",
    "    model_filename = f\"updated_xgb_model_iteration_{iteration + 1}.pkl\"\n",
    "    with open(model_filename, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "    print(f\"Model saved: {model_filename}\")\n",
    "\n",
    "    iteration += 1\n",
    "\n",
    "print(\"Semi-supervised learning process completed.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7039525,
     "sourceId": 11262721,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7036244,
     "sourceId": 11265329,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
