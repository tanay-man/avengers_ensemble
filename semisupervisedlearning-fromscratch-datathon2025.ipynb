{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11265329,"sourceType":"datasetVersion","datasetId":7036244}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pickle\nimport numpy as np\nimport xgboost as xgb\nimport pandas as pd\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport optuna","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:18:36.066320Z","iopub.execute_input":"2025-04-03T18:18:36.066582Z","iopub.status.idle":"2025-04-03T18:18:37.962839Z","shell.execute_reply.started":"2025-04-03T18:18:36.066557Z","shell.execute_reply":"2025-04-03T18:18:37.961832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/datathon2025/final_preprocessed_train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/datathon2025/final_preprocessed_test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:18:37.964081Z","iopub.execute_input":"2025-04-03T18:18:37.964722Z","iopub.status.idle":"2025-04-03T18:18:38.040739Z","shell.execute_reply.started":"2025-04-03T18:18:37.964674Z","shell.execute_reply":"2025-04-03T18:18:38.039630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:18:38.043220Z","iopub.execute_input":"2025-04-03T18:18:38.043586Z","iopub.status.idle":"2025-04-03T18:18:38.088910Z","shell.execute_reply.started":"2025-04-03T18:18:38.043557Z","shell.execute_reply":"2025-04-03T18:18:38.087728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data.drop(columns=[\"Unnamed: 0\"], inplace=True, errors=\"ignore\")\ntest_data.drop(columns=[\"Unnamed: 0\"], inplace=True, errors=\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:18:38.090094Z","iopub.execute_input":"2025-04-03T18:18:38.090512Z","iopub.status.idle":"2025-04-03T18:18:38.097486Z","shell.execute_reply.started":"2025-04-03T18:18:38.090476Z","shell.execute_reply":"2025-04-03T18:18:38.096353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"iteration = 0\nconfidence_threshold = 60","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:18:38.098536Z","iopub.execute_input":"2025-04-03T18:18:38.098812Z","iopub.status.idle":"2025-04-03T18:18:38.118774Z","shell.execute_reply.started":"2025-04-03T18:18:38.098787Z","shell.execute_reply":"2025-04-03T18:18:38.117606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 800, 1500, step=50),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n        \"gamma\": trial.suggest_float(\"gamma\", 0, 10),\n        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 1),\n        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 1)\n    }\n    model = xgb.XGBRegressor(**params, random_state=42)\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    return np.sqrt(mean_squared_error(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:18:38.119871Z","iopub.execute_input":"2025-04-03T18:18:38.120276Z","iopub.status.idle":"2025-04-03T18:18:38.137540Z","shell.execute_reply.started":"2025-04-03T18:18:38.120214Z","shell.execute_reply":"2025-04-03T18:18:38.136278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"while not test_data.empty:\n    print(f\"Iteration {iteration + 1}: Hyperparameter tuning and training model...\")\n\n    # Prepare training data\n    X = train_data.drop(columns=[\"SalePrice\"])\n    y = train_data[\"SalePrice\"]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Perform hyperparameter tuning\n    study = optuna.create_study(direction=\"minimize\")\n    study.optimize(objective, n_trials=200)  # Increase trials to 500\n    best_params = study.best_params\n    best_rmse = study.best_value\n    \n    print(f\"Best hyperparameters found: {best_params}\")\n    print(f\"Best RMSE obtained: {best_rmse}\")\n    \n    # Train final model with best hyperparameters\n    model = xgb.XGBRegressor(**best_params, random_state=42)\n    model.fit(X, y)\n\n    # Predict on test set\n    test_features = test_data.drop(columns=[\"SalePrice\", \"Confidence_Percentage\"], errors=\"ignore\")\n    predictions = model.predict(test_features)\n\n    # Bootstrap sampling for uncertainty estimation\n    n_samples = 40\n    bootstrap_preds = []\n    for _ in range(n_samples):\n        sample_data = resample(test_features)\n        preds = model.predict(sample_data)\n        bootstrap_preds.append(preds)\n    bootstrap_preds = np.array(bootstrap_preds)\n\n    # Compute mean and standard deviation\n    mean_predictions = bootstrap_preds.mean(axis=0)\n    std_predictions = bootstrap_preds.std(axis=0)\n\n    confidence_percentage = 100 * (1 - (std_predictions / (std_predictions.max() + 1e-6)))\n    confidence_percentage = np.clip(confidence_percentage, 0, 100)\n\n    # Store results\n    results_df = test_data.copy()\n    results_df[\"SalePrice\"] = mean_predictions\n    results_df[\"Confidence_Percentage\"] = confidence_percentage\n\n    # Select high-confidence predictions\n    filtered_df = results_df[results_df[\"Confidence_Percentage\"] > confidence_threshold].drop(columns=[\"Confidence_Percentage\"])\n\n    if filtered_df.empty:\n        print(\"No more high-confidence samples. Stopping training.\")\n        break\n\n    # Update training and test data\n    train_data = pd.concat([train_data, filtered_df], ignore_index=True)\n    test_data = test_data.drop(filtered_df.index).reset_index(drop=True)\n    \n    # Print remaining test dataset size\n    print(f\"Remaining test dataset size: {len(test_data)}\")\n\n    train_data.to_csv(f\"final_train_data_ssl{iteration+1}.csv\", index=False)\n\n    # Save updated model\n    model_filename = f\"updated_xgb_model_iteration_{iteration + 1}.pkl\"\n    with open(model_filename, \"wb\") as file:\n        pickle.dump(model, file)\n    print(f\"Model saved: {model_filename}\")\n\n    iteration += 1\n\nprint(\"Semi-supervised learning process completed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:18:38.138643Z","iopub.execute_input":"2025-04-03T18:18:38.138949Z","execution_failed":"2025-04-03T18:58:50.739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}